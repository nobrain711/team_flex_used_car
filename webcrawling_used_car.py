import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import random
from tqdm import tqdm

# -----------------------------
# 1. í¬ë¡¤ë§ ëŒ€ìƒ ì„¤ì •
# -----------------------------
target_brands = [
    ("í˜„ëŒ€", 3, 20), ("ê¸°ì•„", 49, 20), ("ì œë„¤ì‹œìŠ¤", 101, 15),
    ("ì‰ë³´ë ˆ", 4, 15), ("ë¥´ë…¸ì½”ë¦¬ì•„", 5, 10),
    ("BMW", 6, 15), ("ë²¤ì¸ ", 21, 15), ("ì•„ìš°ë””", 18, 10)
]

base_url_template = "https://www.bobaedream.co.kr/mycar/mycar_list.php?gubun={}&maker_no={}&page={}"

urls = []
for brand_name, maker_no, page_cnt in target_brands:
    gubun = "K" if maker_no in [3, 4, 5, 49, 101] else "I"
    for page in range(1, page_cnt + 1):
        urls.append((brand_name, base_url_template.format(gubun, maker_no, page)))


def clean_number(text):
    if not text: return None
    nums = re.sub(r"[^\d]", "", text)
    return int(nums) if nums else None


# í—¤ë” ì •ë³´ë¥¼ ë” ì‹¤ì œ ë¸Œë¼ìš°ì €ì™€ ë¹„ìŠ·í•˜ê²Œ ë³´ê°•í•©ë‹ˆë‹¤.
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
    "Referer": "https://www.bobaedream.co.kr/"
}

cars_data = []

# -----------------------------
# 3. í¬ë¡¤ë§ ì‹œì‘
# -----------------------------
print(f"ğŸš€ ì•ˆì •ì„± ê°•í™” ëª¨ë“œë¡œ ìˆ˜ì§‘ì„ ì¬ì‹œì‘í•©ë‹ˆë‹¤...")
pbar = tqdm(urls, desc="ì „ì²´ ì§„í–‰ ìƒí™©")

for brand_hint, url in pbar:
    try:
        # ëª©ë¡ í˜ì´ì§€ ìš”ì²­
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "lxml")

        # [ìˆ˜ì •] ë³´ë°°ë“œë¦¼ì˜ ì—¬ëŸ¬ ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ì„ ëª¨ë‘ ì²´í¬í•©ë‹ˆë‹¤.
        # ì¼ë°˜ ë¦¬ìŠ¤íŠ¸í˜• í˜¹ì€ ê°¤ëŸ¬ë¦¬í˜• ë“± êµ¬ì¡°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
        car_items = soup.find_all("li", class_=re.compile("product-item|actual-item"))

        if not car_items:
            # ë‹¤ë¥¸ í´ë˜ìŠ¤ëª… ì‹œë„
            car_items = soup.select("div.mode-cell.list-data")

        if not car_items:
            continue

        for car in car_items:
            try:
                # ìƒì„¸ í˜ì´ì§€ ë§í¬ ì¶”ì¶œ ì‹œë„
                a_tag = car.find("a", href=True)
                if not a_tag or 'view' not in a_tag['href']: continue
                link = "https://www.bobaedream.co.kr" + a_tag["href"]

                # ğŸ›‘ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•´ ë§¤ ìƒì„¸í˜ì´ì§€ë§ˆë‹¤ 0.7 ~ 1.2ì´ˆ ëœë¤ ëŒ€ê¸°
                time.sleep(random.uniform(0.7, 1.2))

                res2 = requests.get(link, headers=headers, timeout=5)
                # ë§Œì•½ ì„œë²„ê°€ ì°¨ë‹¨í–ˆë‹¤ë©´ ì‘ë‹µ ì½”ë“œê°€ 200ì´ ì•„ë‹˜
                if res2.status_code != 200:
                    continue

                soup2 = BeautifulSoup(res2.text, "lxml")

                # ìƒì„¸ ì •ë³´ ì¶”ì¶œ (íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”)
                name_tag = soup2.find("h3", class_="tit")
                if not name_tag: continue
                name = name_tag.get_text(strip=True)

                state = soup2.find("div", class_="tbl-01 st-low")
                if not state: continue

                # í”„ë¡œì íŠ¸ í•„ìˆ˜ ì»¬ëŸ¼
                th_elements = state.find_all("th")
                info_dict = {}
                for th in th_elements:
                    key = th.get_text(strip=True)
                    val = th.find_next_sibling("td").get_text(strip=True) if th.find_next_sibling("td") else ""
                    info_dict[key] = val

                price_tag = soup2.find("span", class_="price")
                price_text = price_tag.get_text(strip=True) if price_tag else "0"

                cars_data.append({
                    "brand": brand_hint,
                    "model": name.replace(brand_hint, "").strip(),
                    "year": clean_number(info_dict.get("ì—°ì‹", "")[:4]),
                    "price_krw": clean_number(price_text) * 10000 if "ë§Œ" in price_text else clean_number(price_text),
                    "mileage_km": clean_number(info_dict.get("ì£¼í–‰ê±°ë¦¬", "")),
                    "fuel_type": info_dict.get("ì—°ë£Œ", ""),
                    "transmission": info_dict.get("ë³€ì†ê¸°", ""),
                    "body_type": info_dict.get("ì°¨ì¢…", ""),
                    "displacement_cc": clean_number(info_dict.get("ë°°ê¸°ëŸ‰", "")),
                    "link": link
                })
                pbar.set_postfix(ìˆ˜ì§‘ê±´ìˆ˜=len(cars_data))

            except Exception:
                continue

    except Exception as e:
        time.sleep(5)  # í° ì—ëŸ¬ ë°œìƒ ì‹œ ê¸¸ê²Œ íœ´ì‹
        continue

# -----------------------------
# 4. ìµœì¢… ë°ì´í„° ì €ì¥
# -----------------------------
if cars_data:
    df = pd.DataFrame(cars_data)
    df = df.drop_duplicates(subset=['link'])
    df.to_csv("used_cars_fix.csv", index=False, encoding="utf-8-sig")
    print(f"\nâœ… ì„±ê³µ! ì´ {len(df)}ê±´ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("\nâŒ ì—¬ì „íˆ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë³´ë°°ë“œë¦¼ ì¸¡ì—ì„œ IPë¥¼ ì¼ì‹œ ì°¨ë‹¨í–ˆì„ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.")